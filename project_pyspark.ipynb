{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\nfrom pyspark.ml.feature import StringIndexer, OneHotEncoderEstimator, StandardScaler, VectorAssembler\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql.types import DoubleType"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["spark1 = SparkSession.builder.appName('ds504_projet').getOrCreate()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["df_raw = spark1.read.csv(\"/FileStore/tables/2018.csv\", inferSchema=True, header=True).drop('latitude', 'longitude', 'open_y')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["df_raw.count()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">138</span><span class=\"ansired\">]: </span>203853</div>"]}}],"execution_count":4},{"cell_type":"code","source":["def get_dummy(df,categoricalCols,continuousCols,labelCol):\n  \"\"\"\n  function for encoding categorical features and combine with numeric features.\n  \"\"\"\n  from pyspark.ml import Pipeline\n  from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n  from pyspark.sql.functions import col\n\n  indexers = [ StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c))\n               for c in categoricalCols ]\n\n  # default setting: dropLast=True\n  encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),\n               outputCol=\"{0}_encoded\".format(indexer.getOutputCol()))\n               for indexer in indexers ]\n\n  assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]\n                              + continuousCols, outputCol=\"features\")\n\n  pipeline = Pipeline(stages=indexers + encoders + [assembler])\n\n  model=pipeline.fit(df)\n  data = model.transform(df)\n\n  data = data.withColumn('label',col(labelCol))\n\n  return data.select('features','label')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["# data processing for classifiers\ncatcols = ['reason', 'department', 'neighborhood', 'source']\nnum_cols = ['open_m', 'open_day_of_week', 'Avg Temp (F)', 'Precip (in)']\nlabelCol = 'class'\n\ndata = get_dummy(df_raw,catcols,num_cols,labelCol)\ndata.show(5)\n\n# Split the data into training and test sets (10% held out for testing)\n(trainingData, testData) = data.randomSplit([0.9, 0.1], seed=0)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+-----+\n            features|label|\n+--------------------+-----+\n(88,[17,42,56,79,...|    0|\n(88,[3,42,56,78,8...|    0|\n(88,[5,43,60,79,8...|    0|\n(88,[3,42,69,78,8...|    1|\n(88,[16,47,66,79,...|    1|\n+--------------------+-----+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["# classifications\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.classification import GBTClassifier\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml.classification import MultilayerPerceptronClassifier\n\n\n\nfor c in ['Logistic regression', 'Random forest', 'GBT', 'MPC']:\n  if c == 'Logistic regression':\n    clf = LogisticRegression(featuresCol='features', labelCol='label')\n  elif c == 'Random forest':\n    clf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", seed=0, featureSubsetStrategy='sqrt')\n  elif c == 'GBT':\n    clf = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", seed=0)\n  elif c == 'Decision tree':\n    clf = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", seed=0)\n  elif c == 'MPC':\n    clf = MultilayerPerceptronClassifier(labelCol=\"label\", featuresCol=\"features\", seed=0, layers=[88,3,2])\n  \n  \n  model = clf.fit(trainingData)\n  predictions = model.transform(testData)\n  evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n  accuracy = evaluator.evaluate(predictions)\n  \n  print(c)\n  print('Accuracy: %.2f' % accuracy)\n  print('=====================')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Logistic regression\nAccuracy: 0.77\n=====================\nRandom forest\nAccuracy: 0.75\n=====================\nGBT\nAccuracy: 0.80\n=====================\nMPC\nAccuracy: 0.77\n=====================\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["# data processing for regressors\ncatcols = ['department', 'neighborhood', 'source']\nnum_cols = ['open_m', 'open_day_of_week', 'Avg Temp (F)', 'Precip (in)']\nlabelCol = 'duration'\n\ndata = get_dummy(df_raw.where(df_raw['reason']=='Sanitation'),catcols,num_cols,labelCol)\ndata.show(5)\n\n(trainingData, testData) = data.randomSplit([0.9, 0.1], seed=0)\n# df_raw.where(df_raw['reason']=='Sanitation').show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+-------------------+\n            features|              label|\n+--------------------+-------------------+\n(30,[0,14,24,26,2...| 0.7908333333333334|\n(30,[0,16,24,26,2...|             4.3925|\n(30,[0,9,25,26,28...| 101.85805555555555|\n(30,[0,15,24,26,2...|0.32472222222222225|\n(30,[0,16,24,26,2...| 17.351111111111113|\n+--------------------+-------------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["# regressions\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.regression import DecisionTreeRegressor\nfrom pyspark.ml.regression import RandomForestRegressor\nfrom pyspark.ml.regression import GBTRegressor\n\n\nfor r in ['Linear regression', 'Decision tree', 'Random forest', 'GBT']:\n  if r == 'Linear regression':\n    reg = LinearRegression(featuresCol='features', labelCol='label')\n  elif r == 'Decision tree':\n    reg = DecisionTreeRegressor(featuresCol='features', labelCol='label', seed=0)\n  elif r == 'Random forest':\n    reg = RandomForestRegressor(featuresCol='features', labelCol='label', seed=0, featureSubsetStrategy='sqrt')\n  elif r == 'GBT':\n    reg = GBTRegressor(featuresCol='features', labelCol='label', seed=0)\n  \n  model = reg.fit(trainingData)\n  predictions = model.transform(testData)\n  evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n  r2 = evaluator.evaluate(predictions)\n  \n  print(r)\n  print('R2: %.2f' % r2)\n  print('====================')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Linear regression\nR2: 0.11\n====================\nDecision tree\nR2: 0.08\n====================\nRandom forest\nR2: 0.09\n====================\nGBT\nR2: 0.14\n====================\n</div>"]}}],"execution_count":9}],"metadata":{"name":"DS504","notebookId":649795711660506},"nbformat":4,"nbformat_minor":0}
